{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding\n",
    "\n",
    "## Universidade Federal de Lavras\n",
    "\n",
    "### Agosto de 2022\n",
    "\n",
    "Elaborado por: <a href=\"https://github.com/Victorgonl\">Victor Gonçalves Lima</a>\n",
    "\n",
    "Orientado por: <a href=\"https://sites.google.com/ufla.br/denilsonpereira/\">Prof. Denilson Alves Pereira</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definições\n",
    "\n",
    "## Processamento de Linguagens Naturais (NLP)\n",
    "\n",
    "- Subcampo de línguistica, ciências da computação e inteligência artificial que estuda como computadores processam e analizam dados de **linguagem natural** humana.\n",
    "\n",
    "## Word Embedding\n",
    "\n",
    "- Termo que se refere à representação de palavras para análises textuais, de forma que vetores usados para codificar certa palavra seja espacialmente próximo aos vetores de palavras similares.\n",
    "\n",
    "- Podem ser obtidos através de **modelos de linguagens**, onde palavras e sentenças são mapeadas em vetores de números reais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abordagens para representação de palavras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary Lookup\n",
    "\n",
    "- Método que atribui uma identificação para cada palavra.\n",
    "\n",
    "- Pode utilizar **lemmatisation** e **stemming** para converter palavras para sua forma básica, sem conjugações por exemplo.\n",
    "\n",
    "- Um valor que não pertence ao vocabulário é chamado **out of vocabulary**.\n",
    "\n",
    "- **Out of vocabulary** é representado pelo número do tamanho *n* do vocabulário.\n",
    "\n",
    "- Por trabalhar com números inteiros, os modelos podem, de forma errônea, assumir a existência de ordem pelos IDs.\n",
    "\n",
    "<img src=\"figs/DicionaryLookup.png\" width=\"700\" title=\"https://towardsdatascience.com/word-representation-in-natural-language-processing-part-i-e4cd54fed3d4\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocks\n",
      "walking\n",
      "sleeps\n",
      "learning\n",
      "cars\n",
      "learned\n"
     ]
    }
   ],
   "source": [
    "path_vocab = \"./datasets/words.txt\"\n",
    "\n",
    "words = []\n",
    "n_words = 0\n",
    "\n",
    "with Path(path_vocab).open() as f: \n",
    "    for word in f: \n",
    "        words.append(word.strip())\n",
    "        print(word.strip(), sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep\n",
      "car\n",
      "rock\n",
      "learn\n",
      "walk\n"
     ]
    }
   ],
   "source": [
    "base_words = set()\n",
    "\n",
    "for word in words:\n",
    "    word = WordNetLemmatizer().lemmatize(word)\n",
    "    word = PorterStemmer().stem(word)\n",
    "    base_words.add(word)\n",
    "\n",
    "for word in base_words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID\t\tWord\n",
      "-------\t\t-------\n",
      "0\t\tsleep\n",
      "1\t\tcar\n",
      "2\t\trock\n",
      "3\t\tlearn\n",
      "4\t\twalk\n"
     ]
    }
   ],
   "source": [
    "base_words = list(base_words)\n",
    "\n",
    "print(\"ID\\t\\tWord\")\n",
    "print(\"-------\\t\\t-------\")\n",
    "for i in range(len(base_words)):\n",
    "    print(i, \"\\t\\t\", base_words[i], sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Enconding\n",
    "\n",
    "- É uma representação vetorial onde os vetores possuem o tamanho *n* do vocabulário + 1 (*n + 1*).\n",
    "\n",
    "- O vetor de uma palavra é preenchido de 0s, exceto pela posição que representa a palavra, preenchida por 1.\n",
    "\n",
    "- A posição *n* representa o valor **out of vocabulary**.\n",
    "\n",
    "- Possui vantagem sobre **Dictionary Lookup**, porém requer muita memória para computação devido ao tamanho.\n",
    "\n",
    "<img src=\"figs/One-HotEncoding.png\" width=\"900\" title=\"https://towardsdatascience.com/word-representation-in-natural-language-processing-part-i-e4cd54fed3d4\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributional Representation\n",
    "\n",
    "- Criada a partir do conceito de que palavras que aparecem em contextos similares possuem significados similares.\n",
    "\n",
    "- Apresenta os contextos que uma palavra occore em matriz.\n",
    "\n",
    "- As linhas da tabela representa as palavras do vocabulário e as colunas são seus contextos.\n",
    "\n",
    "- As entradas na tabela são o número de ocorrências de uma palavra em determinado contexto.\n",
    "\n",
    "<img src=\"figs/DistributionalRepresentation.png\" width=\"750\" title=\"https://towardsdatascience.com/word-representation-in-natural-language-processing-part-i-e4cd54fed3d4\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributional Representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Características\n",
    "\n",
    "- Representa palavras como vetores.\n",
    "\n",
    "- Cada entrada no vetor representa uma ***hiden feature*** no significado da palavra.\n",
    "\n",
    "- Podem revelar dependências semânticas e sintáticas.\n",
    "\n",
    "É possível perceber na representação abaixo que 'flight' e 'plane' possuem valores numéricos próximos, assim como 'river' e 'lake'.\n",
    "\n",
    "<img src=\"figs/DistributionalRepresentation-2.png\" width=\"1000\" title=\"https://towardsdatascience.com/word-representation-in-natural-language-processing-part-i-e4cd54fed3d4\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip-Gram (from Word2Vev)\n",
    "\n",
    "- Modelo que faz parte da biblioteca ***Word2Vec***.\n",
    "\n",
    "- A ideia principal é representar palavras através de seus vizinhos.\n",
    "\n",
    "- Tenta prever o contexto de uma determinada palavra.\n",
    "\n",
    "<img src=\"figs/Skip-Gram-Arch.png\" width=\"300\" title=\"https://proceedings.neurips.cc/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf\"/>\n",
    "\n",
    "<h1>\n",
    "<img src=\"figs/Skip-Gram-Model1.png\" width=\"300\" title=\"https://proceedings.neurips.cc/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf\"/>\n",
    "<img src=\"figs/Skip-Gram-Model2.png\" width=\"272\" title=\"https://proceedings.neurips.cc/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf\"/>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe (Global Vectors)\n",
    "\n",
    "- Diferente do ***Word2Vec***, que captura certos contextos locais, ***GloVe*** explora sobre toda estatística de ocorrência da palavra no dataset.\n",
    "\n",
    "### Etapas:\n",
    "\n",
    "- Criar uma matriz de coocorrências de termos.\n",
    "\n",
    "- Para cada palavra, é computado as probabilidades condicionais $P(k|w)$.\n",
    "\n",
    "- $w$ é a palavra sendo analisada e $k$ é uma outra palavra do vocabulário.\n",
    "\n",
    "- Quanto maior o valor de $P$, maior a probabilidade da palavra $w$ estar correlacionada com a palavra $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências\n",
    "\n",
    "- https://proceedings.neurips.cc/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf\n",
    "\n",
    "- https://nlp.stanford.edu/projects/glove/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ANN')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8663c385cbf4c3d22bffee4c42da5889d75ca18cb42650276d47ed31b543a969"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
